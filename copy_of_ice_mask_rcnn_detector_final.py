# -*- coding: utf-8 -*-
"""Copy of Ice_mask_rcnn_detector_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12OuRKf3AksGOjgi0bPoD8SAxRsgS2vRL
"""

!git clone https://github.com/pytorch/vision.git
!cp vision/references/detection/utils.py ./

import os
import ssl
import torch
import torchvision
import utils
import warnings
import numpy as np
import matplotlib.pyplot as plt
from torchvision.transforms.v2 import functional as F
from torchvision import tv_tensors
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.utils import draw_bounding_boxes ,draw_segmentation_masks
from torch.utils.data import Dataset
from PIL import Image
from torchvision.transforms import v2 as T
from torchvision.io import read_image
from torchvision.ops import masks_to_boxes
from tqdm import tqdm
from sklearn.metrics import average_precision_score
from torchvision import transforms

class_str2num = {"Ice": 1}

class IceDataset(Dataset):

    def __init__(self, root, transform=None):
        self.root = root
        self.transform = transform
        self.annotations = self.get_annotations()

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, index):

        img_name, boxes, labels, masks= self.annotations[index]
        img_path = os.path.join(self.root, img_name)
        img = Image.open(img_path).convert("RGB")

        if self.transform:
          img = self.transform(img)

        boxes = tv_tensors.BoundingBoxes(boxes,format="XYXY", canvas_size=F.get_size(img))
        labels = torch.tensor(labels, dtype=torch.int64)
        masks = tv_tensors.Mask(masks)


        target = {"boxes": boxes, "labels": labels, "masks": masks}

        return img, target

    def get_annotations(self):

        # Defining the arrays to hold the annotations and the prefixes of mask files
        annotations = []
        mask_prefixes = ["task", "blob_mask",]
        SAR_prefixes = ["Ant_frame","Arc_frame","Synthetic_image"]
        SAR_filenames =[]
        mask_filenames =[]

        # Getting the correct filename , relavent annotations
        for f in os.listdir(self.root):

          # Check to see if file name belongs in the masks list
           for mprefix in mask_prefixes:
            if mprefix in f:
              mask_filenames.append(f)

          # Check to see if the file name belongs in the SAR list
           for sprefix in SAR_prefixes:
            if sprefix in f:
              SAR_filenames.append(f)

        # Main loop for attaching annotations
        for idx in range(len(SAR_filenames)):
          SAR_filename = SAR_filenames[idx]
          mask_filename = mask_filenames[idx]

          #Appending files to the root path
          SAR_path = os.path.join(self.root,SAR_filename)
          mask_path = os.path.join(self.root,mask_filename)

          if os.path.exists(SAR_path):
            filename = SAR_filename

          if os.path.exists(mask_path):
            bboxes = []
            labels = []
            # Reading the mask image
            mask_filename = read_image(mask_path)

            #Ensuring that there is only one catergory in the real data
            if mask_prefixes[0] in mask_path:
              mask_filename[mask_filename>0] = 255

            # Getting unique object ids
            object_ids = torch.unique(mask_filename)
            # first id is the background, so remove it
            object_ids = object_ids[1:]
            masks = (mask_filename == object_ids[: , None , None]).to(dtype=torch.uint8)

            # Turn the mask of object in an image to boxes
            tensor_boxes = masks_to_boxes(masks)
            for box in tensor_boxes:
              x_min, y_min, x_max, y_max = box.tolist()

              area = (x_max - x_min) * (y_max - y_min)

              if area == 0.0:
                continue
              else:
                bboxes.append([x_min,y_min,x_max,y_max])
                labels.append(class_str2num["Ice"])

          annotations.append((filename,bboxes,labels,masks))

        return annotations

def get_model(number_of_classes):


    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights="DEFAULT")
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, number_of_classes)

    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
    hidden_layer = 256

    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,hidden_layer,number_of_classes)

    return model

def get_transform(train):
    img_transforms = [transforms.ToTensor()]
    if train:
        img_transforms.append(transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))
        img_transforms.append(T.RandomHorizontalFlip(0.5))
    return transforms.Compose(img_transforms)

def calculate_iou(b1,b2):

  x1 = max(b1[0],b2[0])
  y1 = max(b1[1],b2[1])
  x2 = min(b1[2],b2[2])
  y2 = min(b1[3],b2[3])

  intersection_area = max(0,(x2-x1) + 1) * max(0,(y2-y1)+1)

  b1_area = (b1[2] - b1[0] + 1) * (b1[3] - b1[1] + 1)
  b2_area = (b2[2] - b2[0] + 1) * (b2[3] - b2[1] + 1)

  iou = intersection_area/float((b1_area+b2_area)-intersection_area)

  return iou

def match_pred_with_ground(pred,ground,iou_thres = 0.5):

  matched_pairs = []
  unmatched_pred = []

  iou_array = []

  for pbox in pred:
    max_iou = -1
    best_match_index = -1

    for idx,gbox in enumerate(ground):
      iou = calculate_iou(pbox,gbox)
      iou_array.append(iou)
      if iou>max_iou:
        max_iou = iou
        best_match_index = idx

      if max_iou >= iou_thres:
        matched_pairs.append((pbox,ground[best_match_index]))

      else:
        unmatched_pred.append(pbox)

  return matched_pairs,unmatched_pred,iou_array

def train_one_epoch(model, device, optimizer, data_loader, epoch, total_epochs,mnorm):

    model.train()

    mask_losses = []

    progress_bar_epoch = tqdm(total=len(data_loader), desc=f'Epoch {epoch + 1}/{total_epochs}')

    for batch_i, (images,targets) in enumerate(data_loader):


      images = list(image.to(device) for image in images)
      targets = [{k: v.to(device) for k,v in t.items()} for t in targets]

      #Parse images and ground truth labels through the model

      output = model(images,targets)

      mask_loss = output["loss_mask"]

      mask_losses.append(mask_loss.item())

      loss = sum(loss for loss in output.values())

      #Perform backpropagation
      optimizer.zero_grad()
      loss.backward()

      #Usage of gradient clipping to avoid exploding gradient
      torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=mnorm)
      optimizer.step()

      progress_bar_epoch.update(1)
      progress_bar_epoch.set_postfix({'Mask loss': mask_loss.item()})


    average_mask_loss = np.mean(mask_losses)

    progress_bar_epoch.close()

    return average_mask_loss


def evaluate(model, device ,data_loader, detection_threshold,mask_prob_threshold,epoch,total_epochs):
    model.eval()

    average_precision_scores = []

    for batch_i , (images,targets) in enumerate(data_loader):


      '''Setting up empty values to calculate the recall and precision values
         for all bounding boxes detected inside the model '''

      images = list(image.to(device) for image in images)

      with torch.no_grad():
        output = model(images)

      #Getting all prediction boxes that are higher than the detetion threshold
      pred_bboxes = output[0]['boxes'].detach().cpu().numpy()
      #Getting all masks which are higher than the detection threshold
      pred_masks = output[0]['masks'].detach().cpu().numpy()

      # Retrive ground truth bounding boxes
      actual_bboxs = targets[0]["boxes"].cpu().numpy()

      matched,unmatched_pred,iou_array= match_pred_with_ground(pred_bboxes,actual_bboxs)

      if epoch == total_epochs - 1:
        pred_masks = pred_masks.squeeze()
        pred_masks_grayscale = np.uint8(pred_masks * 255)

        try:
          plt.imshow(pred_masks_grayscale, cmap='gray')
          plt.axis('off')
          plt.show()
        except:
          pass

    # Calculating the mean average precision
    mean_iou= np.mean(iou_array)


    return mean_iou

def detect_ice(dataset,number_of_epochs):
      # Supression of SSL checks and warnings
      ssl._create_default_https_context = ssl._create_unverified_context
      warnings.filterwarnings("ignore")


      # Composition of image transforms
      image_transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])


      #Loading in the datasets
      train_dataset = IceDataset(dataset+"/train", transform = get_transform(train=True))
      test_dataset = IceDataset(dataset+"/val", transform = get_transform(train=False))


      # Define the data loaders
      train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2,
                                               collate_fn=utils.collate_fn)

      test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2,
                                              collate_fn=utils.collate_fn)



      # Initialization of the model
      device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
      num_classes = len(class_str2num) + 1
      model = get_model(num_classes)
      model.to(device)


      # Define the optimizer
      params = [p for p in model.parameters() if p.requires_grad]
      optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)


      # Define the learning rate scheduler
      lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)

      # Defining the number of epochs
      num_epochs = number_of_epochs

      epochs = [i for i in range(1,num_epochs+1)]
      average_mask_losses = []
      average_IoUs = []

      for epoch in range(num_epochs):
        print("="*100)
        # Training one epoch
        avg_msk_loss=train_one_epoch(model, device, optimizer, train_loader, epoch=epoch, total_epochs=num_epochs,mnorm=5)
        average_mask_losses.append(avg_msk_loss)
        # Evaluate model
        mIoU = evaluate(model,device,test_loader,detection_threshold=0.5,mask_prob_threshold=0.7,epoch=epoch,total_epochs=num_epochs)
        average_IoUs.append(mIoU)
        print(f"The mean iou score for epoch {epoch+1} is {mIoU*100} %")
        # update the learning rate
        lr_scheduler.step()
        print("="*100)

      print("Here is the average mask loss in the training process across all epochs")

      plt.plot(epochs,average_mask_losses)
      plt.xlabel("Epoch number")
      plt.ylabel("Average mask loss")
      plt.title("Mean average mask loss across number of epoches trained")
      plt.show()

      print("Here is the average IoU in the evaluation process across all epochs")
      plt.plot(epochs,average_IoUs)
      plt.xlabel("Epoch number")
      plt.ylabel("Average IoU")
      plt.title("Mean average IoU across number of epoches evaluated")
      plt.show()

from google.colab import drive
drive.mount('/content/drive')

# Testing the unbalanced data
detect_ice("/content/drive/MyDrive/Dataset/Real",30)

detect_ice("/content/drive/MyDrive/Dataset/Synthetic",100)

detect_ice("/content/drive/MyDrive/Dataset/Hybrid",100)